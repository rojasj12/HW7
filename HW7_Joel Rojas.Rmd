---
title: "HW7 by Joel Rojas"
output: github_document
---
install.packages("knitr")


### Econ B2000, MA Econometrics
### HW7
### Fall 2023

Lab
In this lab, I wanted to understand how different levels of education and age might be related to how often people are involved in public work, specifically for men between 25 and 40 years old.

1.	First, we focused on a particular group of people from a ACS 2017. I chose men who are between 25 and 40 years old. This is because we are interested in understanding the workforce that is likely to have completed their education.

2.	I needed to make sure we had all the variables needed for our analysis, such as education level, age, and public work involvement.

3.	The dataset gives us education levels in many detailed categories. We simplified this into four main categories using "dummy variables" (variables that are either 0 or 1):

•	educ_hs: Is the person a high school graduate: 1 for yes, 0 for no

•	educ_somecoll: Did they attend some college or get an associate's degree: 1 for yes, 0 for no

•	educ_college: Did they get a bachelor's degree: 1 for yes, 0 for no

•	educ_advdeg: Did they get an advanced degree like a Master’s or Ph.D.: 1 for yes, 0 for no

4.	Next, we used these categories and age to build a model to understand their relationship with public work involvement. We used a linear regression model for this

5.	The Results
•	For each additional year of age, public work involvement increases a little (by 0.00123).
•	Having a high school diploma, some college education, a bachelor's degree, or an advanced degree all increase the likelihood of being involved in public work compared to having no education. And the more advanced the degree, the higher the involvement.

Final Project: Academic Articles:

IT’S FOURTH DOWN AND WHAT DOES THE BELLMAN EQUATION SAY? A DYNAMIC-PROGRAMMING ANALYSIS OF FOOTBALL STRATEGY By David Romer

David Romer’s paper, "It’s Fourth Down and What Does the Bellman Equation Say? A Dynamic-Programming Analysis of Football Strategy," offers an innovative approach to analyzing decision-making in American football, particularly during crucial fourth-down moments. Utilizing the Bellman Equation, a key tool in dynamic programming, Romer systematically evaluates the decisions teams make on fourth down, comparing them to optimal strategies derived from his model. His study is grounded in real-world data, as he meticulously examines play-by-play descriptions from NFL games.
Romer’s findings highlight a noticeable trend of conservatism among football coaches, especially when faced with short-yardage situations on fourth down. He posits that teams could substantially improve their winning prospects by adopting more aggressive strategies, such as attempting to achieve a first down, instead of settling for field goals or punts. The study challenges entrenched football strategies and demonstrates how economic theories and quantitative methods can be applied to optimize decision-making in sports.

nflWAR: A Reproducible Method for Offensive Player Evaluation in Football
Ronald Yurko, Samuel Ventura, and Maksim Horowitz Department of Statistics & Data Science, Carnegie Mellon University

This paper addresses the need for comprehensive and reproducible statistical ratings for player evaluation in American football, presenting a series of innovative solutions to bridge the gap. The authors introduce the nflscrapR package, providing easy access to extensive NFL play-by-play data, and propose a multinomial logistic regression model to estimate the expected points for each play. They further utilize these expected points in a generalized additive model to calculate win probabilities for each play. A major contribution of this work is the development of the nflWAR framework, which employs multilevel models to isolate individual offensive skill players’ contributions, quantifying their impact in terms of Wins Above Replacement (WAR). The authors provide detailed WAR estimates along with uncertainty measurements for players based on the 2017 NFL season, emphasizing the reproducibility of their approach with publicly available data. They underscore the potential of their framework to be extended for evaluating players across different positions, heralding a new era of data-driven decision-making and player evaluation in football.




  
We will start the first of a 3-part sequence.

Upon Claudia Goldin being named for Nobel Prize this month, I was talking with a colleague, Prof Norma Fuentes-Mayorga. She described her hypothesis about female labor force participation and especially choices to work in the public sector, in jobs that are more stable. She has heard this rationale in numerous interviews, particularly among minoritized women, but we'd like to see if there is more evidence for this. I have created an indicator (public_work) in the ACS2021 data, based on the industry that the person works in.

In the first part, we will use basic OLS to estimate some models of the choice to work in public sector. In second part (next week) we'll estimate with logit and probit models. In third part (week after) we'll use some additional machine-learning techniques.

We'll start by discussing what is appropriate specification of interaction terms, to find evidence of this effect. In your group you can discuss about what subset is most relevant and how exactly you'd implement the estimation. Then you will work on some results, come back and share.

You'll have to download a couple csv definition files, `IND_levels.csv` and `publicwork_recode.csv`. Then you should first run these:

```{r eval=FALSE}
require(plyr)
require(dplyr)
require(tidyverse)
require(haven)
install.packages("knitr")

levels_n <- read.csv("IND_levels.csv")
names(levels_n) <- c("New_Level","levels_orig")
acs2017$IND <- as.factor(acs2017$IND)
levels_orig <- levels(acs2017$IND) 
levels_new <- join(data.frame(levels_orig),data.frame(levels_n))

acs2017$public_work <- acs2017$IND 
levels_public <- read.csv("publicwork_recode.csv")
names(levels_public) <- c("levels_orig","New_Level")
levels_new_pub <- join(data.frame(levels_orig),data.frame(levels_public))


levels(acs2017$IND) <- levels_new$New_Level
levels(acs2017$public_work) <- levels_new_pub$New_Level


```

Now before you run to estimate a model, in general it is a good idea to check summary stats before doing fancier models. For example look at the fractions by education, maybe do some statistics like you ~~did~~ should have done in exam.

R doesn't want a factor as dependent variable in lm() call, so we create a numeric version,
```{r eval=FALSE}
acs2017$public_work_num <- as.numeric(acs2017$public_work == "work for public, stable")
```
Although other functions will take a factor. That can be trouble so be careful! All the math underlying is just concerned with which of the x-variables make the y-variable more likely to be a higher number. In this case it's ok, I've set it up but in general you want to confirm which factor answer is one and which is zero.

For instance,
```{r eval=TRUE}
table(acs2017$public_work,acs2017$public_work_num)
```
shows that a one corresponds to 'yes the person does work for public and/or in a generally stable job'. But a different person could estimate a model where the dependent variable is 'yes the person works in private sector' and that would have different signs for the estimated coefficients! Either model could be sensible, as long as you're clear about which one the computer is estimating. Be paranoid and check.

You can estimate models something like this (once you figure out what subset of data you'll use)
```{r eval=TRUE}


library(dplyr)

acs2017 <- acs2017 %>%
  mutate(
    educ_hs = ifelse(EDUCD >= 060 & EDUCD <= 064, 1, 0),  
    educ_somecoll = ifelse(EDUCD >= 065 & EDUCD <= 083, 1, 0),  
    educ_college = ifelse(EDUCD >= 090 & EDUCD <= 101, 1, 0),  
    educ_advdeg = ifelse(EDUCD >= 110, 1, 0)  
  )


acs2017_subset <- acs2017 %>% 
  filter(SEX == 1, AGE >= 25, AGE <= 40)


ols_out1 <- lm(public_work_num ~ educ_hs + educ_somecoll + educ_college + educ_advdeg + AGE, data = acs2017)
summary(ols_out1)


```






